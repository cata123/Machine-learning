{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificacion de imagenes daño mineria.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PcGYcWxvLHR2xf6B70S2gFBExJ0iOEMH",
      "authorship_tag": "ABX9TyNDtt7HT58JRTHQGWZl64c4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cata123/Machine-learning/blob/main/Clasificacion_de_imagenes_da%C3%B1o_mineria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV3OQnlGi5K5"
      },
      "source": [
        "**Clasificación de imágenes con daños por mineria con red convolucional**\n",
        "Integrantes: Laura Guzmán\n",
        "            Fabian Duarte\n",
        "            Nicolás Claros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tY7XcnaPtra",
        "outputId": "479fc954-3169-4a41-e4a7-db762db9bc1d"
      },
      "source": [
        "!pip install keras\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x1yi2pTzyoL"
      },
      "source": [
        "\n",
        "#Importar las librerias \n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#rom keras.utils import to_categorical\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vgCh2UVMtIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62ad6fa-ded8-4f11-e51a-a29385effdff"
      },
      "source": [
        "#Cargar set de Imágenes\n",
        "dirname = os.path.join(os.getcwd(), 'imagenesM')\n",
        "imgpath = dirname + os.sep \n",
        "\n",
        "images = []\n",
        "directories = []\n",
        "dircount = []\n",
        "prevRoot=''\n",
        "cant=0\n",
        "\n",
        "print(\"leyendo imagenes de \",imgpath)\n",
        "\n",
        "for root, dirnames, filenames in os.walk(imgpath):\n",
        "    for filename in filenames:\n",
        "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
        "            cant=cant+1\n",
        "            filepath = os.path.join(root, filename)\n",
        "            image = plt.imread(filepath)\n",
        "            images.append(image)\n",
        "            b = \"Leyendo...\" + str(cant)\n",
        "            print (b, end=\"\\r\")\n",
        "            if prevRoot !=root:\n",
        "                print(root, cant)\n",
        "                prevRoot=root\n",
        "                directories.append(root)\n",
        "                dircount.append(cant)\n",
        "                cant=0\n",
        "dircount.append(cant)\n",
        "\n",
        "dircount = dircount[1:]\n",
        "dircount[0]=dircount[0]+1\n",
        "print('Directorios leidos:', len(directories))\n",
        "print(\"Imagenes en cada directorio\", dircount)\n",
        "print('suma Total de imagenes en subdirectorios:',sum(dircount))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "leyendo imagenes de  /content/imagenesM/\n",
            "Leyendo...1\r/content/imagenesM/suelo 1\n",
            "Leyendo...1\rLeyendo...2\rLeyendo...3\rLeyendo...4\rLeyendo...5\rLeyendo...6\rLeyendo...7\rLeyendo...8\rLeyendo...9\rLeyendo...10\rLeyendo...11\rLeyendo...12\rLeyendo...13\rLeyendo...14\rLeyendo...15\rLeyendo...16\rLeyendo...17\rLeyendo...18\rLeyendo...19\rLeyendo...20\rLeyendo...21\rLeyendo...22\rLeyendo...23\rLeyendo...24\rLeyendo...25\rLeyendo...26\rLeyendo...27\rLeyendo...28\rLeyendo...29\rLeyendo...30\rLeyendo...31\rLeyendo...32\rLeyendo...33\rLeyendo...34\rLeyendo...35\rLeyendo...36\rLeyendo...37\rLeyendo...38\rLeyendo...39\rLeyendo...40\rLeyendo...41\rLeyendo...42\rLeyendo...43\rLeyendo...44\rLeyendo...45\rLeyendo...46\rLeyendo...47\rLeyendo...48\rLeyendo...49\rLeyendo...50\rLeyendo...51\rLeyendo...52\rLeyendo...53\rLeyendo...54\rLeyendo...55\rLeyendo...56\rLeyendo...57\rLeyendo...58\rLeyendo...59\rLeyendo...60\rLeyendo...61\rLeyendo...62\rLeyendo...63\rLeyendo...64\rLeyendo...65\rLeyendo...66\rLeyendo...67\rLeyendo...68\rLeyendo...69\rLeyendo...70\rLeyendo...71\rLeyendo...72\rLeyendo...73\rLeyendo...74\rLeyendo...75\rLeyendo...76\rLeyendo...77\r/content/imagenesM/paisaje 77\n",
            "/content/imagenesM/agua 117\n",
            "Directorios leidos: 3\n",
            "Imagenes en cada directorio [78, 117, 73]\n",
            "suma Total de imagenes en subdirectorios: 268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y8E5vsGMyW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0153101-2b40-440d-bd5a-e97b5a315be5"
      },
      "source": [
        "#Creamos las etiquetas\n",
        "labels=[]\n",
        "indice=0\n",
        "for cantidad in dircount:\n",
        "    for i in range(cantidad):\n",
        "        labels.append(indice)\n",
        "    indice=indice+1\n",
        "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
        "\n",
        "impactos=[]\n",
        "indice=0\n",
        "for directorio in directories:\n",
        "    name = directorio.split(os.sep)\n",
        "    print(indice , name[len(name)-1])\n",
        "    impactos.append(name[len(name)-1])\n",
        "    indice=indice+1\n",
        "    \n",
        "print('Array imagenes: ', len(images))\n",
        "y = np.array(labels)\n",
        "X = np.array([images], dtype=object) #convierto de lista a numpy\n",
        "#X = np.asarray(images).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad etiquetas creadas:  268\n",
            "0 suelo\n",
            "1 paisaje\n",
            "2 agua\n",
            "Array imagenes:  268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfnHvoLCM2x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d06cde-a823-4d91-ad65-e71e3ab66905"
      },
      "source": [
        "#Encontrar el número de cada etiqueta de entrenamiento\n",
        "classes = np.unique(y)\n",
        "nClasses = len(classes)\n",
        "print('Total número de salidas : ', nClasses)\n",
        "print('Output classes : ', classes)\n",
        "\n",
        "print('Valor de X:', X.shape)\n",
        "print('Valor de y:', y.shape)\n",
        "\n",
        "X = X.reshape(X.shape[1:])\n",
        "print('Valor de X:', X.shape)\n",
        "X = X.transpose()\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total número de salidas :  3\n",
            "Output classes :  [0 1 2]\n",
            "Valor de X: (1, 268)\n",
            "Valor de y: (268,)\n",
            "Valor de X: (268,)\n",
            "(268,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9aQ8xpdM5pB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb1bca6-1a1e-46d2-f9d8-2b69c0e804f5"
      },
      "source": [
        "#Crear los grupos de entrenamiento\n",
        "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
        "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
        "print('Testing data shape : ', test_X.shape, test_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (214,) (214,)\n",
            "Testing data shape :  (54,) (54,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzBj0vX7Zq_B",
        "outputId": "3addc67f-2aeb-4852-eaba-cbf66ab1ee6c"
      },
      "source": [
        "#Dividimos las imagenes en grupos para que sea mas facil el entrenamiento\n",
        "train_X = train_X.astype('object')\n",
        "test_X = test_X.astype('object')\n",
        "train_X = train_X / 54.0\n",
        "test_X = test_X / 54.0\n",
        " \n",
        "# Change the labels from categorical to one-hot encoding\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        " \n",
        "# Display the change for category label using one-hot encoding\n",
        "print('Original label:', train_Y[0])\n",
        "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
        "#División de la información a ser entrenada\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
        " \n",
        "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original label: 0\n",
            "After conversion to one-hot: [1. 0. 0.]\n",
            "(171,) (43,) (171, 3) (43, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COxYPNi8Z9Iz",
        "outputId": "7fb0ed6f-300a-4fa6-d82c-b77c3815318c"
      },
      "source": [
        "#Se definene las configuraciones de la red neuronal convolucional\n",
        "INIT_LR = 1e-3\n",
        "epochs = 6\n",
        "batch_size = 64\n",
        "\n",
        "sport_model = Sequential()\n",
        "sport_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(21,28,3)))\n",
        "sport_model.add(LeakyReLU(alpha=0.1))\n",
        "sport_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "sport_model.add(Dropout(0.5))\n",
        "\n",
        "sport_model.add(Flatten())\n",
        "sport_model.add(Dense(32, activation='linear'))\n",
        "sport_model.add(LeakyReLU(alpha=0.1))\n",
        "sport_model.add(Dropout(0.5)) \n",
        "sport_model.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "sport_model.summary()\n",
        "\n",
        "sport_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 21, 28, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 21, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 11, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4928)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                157728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 158,723\n",
            "Trainable params: 158,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "2q7QfCFGaBG5",
        "outputId": "8620cd9d-4d3d-4ef6-d24f-14801cc31c30"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_X[80])\n",
        "plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyHAcbc9dSA5"
      },
      "source": [
        "#Definición del modelo de las etapas con las capas de las neuronas para aprender\n",
        "model = keras.Sequential([keras.layers.Flatten(input_shape = (21, 28)), keras.layers.Dense(32, activation = tf.nn.relu), keras.layers.Dense(10, activation = tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uPCSSC6kzhp"
      },
      "source": [
        "#Evaluar el entrenamiento\n",
        "#model.compile(optimizer = tf.train.AdamOptimizer(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "FR02EnODmVKS",
        "outputId": "faa47970-82d6-49b4-b585-7f7cd20ef1a3"
      },
      "source": [
        "#Empezamos a entrenar\n",
        "model.fit(train_X, train_Y, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-0b40a9cecd2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Empezamos a entrenar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m                **kwargs):\n\u001b[1;32m    230\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    233\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m   1430\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1431\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    }
  ]
}